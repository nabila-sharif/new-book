"use strict";(self.webpackChunkfrontend_book=self.webpackChunkfrontend_book||[]).push([[5680],{7704(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4/chapter-2-content","title":"Chapter 2: Cognitive Planning with LLMs","description":"Chapter 2: Cognitive Planning with LLMs","source":"@site/docs/module-4/chapter-2-content.md","sourceDirName":"module-4","slug":"/module-4/chapter-2-content","permalink":"/docs/module-4/chapter-2-content","draft":false,"unlisted":false,"editUrl":"https://github.com/nabila-sharif/AI---Humanoid-Robotics-Book/tree/main/frontend_book/docs/module-4/chapter-2-content.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Chapter 2: Cognitive Planning with LLMs"},"sidebar":"module4Sidebar","previous":{"title":"Chapter 1: Voice-to-Action Interfaces","permalink":"/docs/module-4/chapter-1-content"},"next":{"title":"Chapter 3: Capstone Project - Autonomous Humanoid","permalink":"/docs/module-4/chapter-3-content"}}');var i=t(4848),o=t(8453);const s={sidebar_position:2,title:"Chapter 2: Cognitive Planning with LLMs"},r=void 0,l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Topics",id:"key-topics",level:2},{value:"1. LLM Integration for Cognitive Planning",id:"1-llm-integration-for-cognitive-planning",level:3},{value:"Basic LLM Integration",id:"basic-llm-integration",level:4},{value:"2. Goal Decomposition Techniques",id:"2-goal-decomposition-techniques",level:3},{value:"Hierarchical Task Decomposition",id:"hierarchical-task-decomposition",level:4},{value:"3. Task Sequencing with LLMs",id:"3-task-sequencing-with-llms",level:3},{value:"Sequential Task Planner",id:"sequential-task-planner",level:4},{value:"4. Prompt Engineering Examples for Robotics",id:"4-prompt-engineering-examples-for-robotics",level:3},{value:"Context-Aware Prompting",id:"context-aware-prompting",level:4},{value:"5. Error Handling and Replanning Strategies",id:"5-error-handling-and-replanning-strategies",level:3},{value:"Robust Planning with Error Handling",id:"robust-planning-with-error-handling",level:4},{value:"6. Safety Constraints Implementation",id:"6-safety-constraints-implementation",level:3},{value:"Safety-Constrained Planning",id:"safety-constrained-planning",level:4},{value:"7. Complete Cognitive Planning System",id:"7-complete-cognitive-planning-system",level:3},{value:"Assessment Criteria",id:"assessment-criteria",level:2}];function p(n){const e={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.p,{children:"Chapter 2: Cognitive Planning with LLMs"}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Integrate LLMs for cognitive planning in robotics applications"}),"\n",(0,i.jsx)(e.li,{children:"Apply goal decomposition and task sequencing techniques"}),"\n",(0,i.jsx)(e.li,{children:"Translate natural language goals into ROS 2 action graphs"}),"\n",(0,i.jsx)(e.li,{children:"Create effective prompt engineering examples for robotics"}),"\n",(0,i.jsx)(e.li,{children:"Implement error handling and replanning strategies"}),"\n",(0,i.jsx)(e.li,{children:"Include safety constraints in cognitive planning systems"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"key-topics",children:"Key Topics"}),"\n",(0,i.jsx)(e.h3,{id:"1-llm-integration-for-cognitive-planning",children:"1. LLM Integration for Cognitive Planning"}),"\n",(0,i.jsx)(e.p,{children:"Large Language Models (LLMs) can serve as cognitive planners that interpret high-level goals and generate executable action sequences for robots. This approach enables natural language interaction with robotic systems."}),"\n",(0,i.jsx)(e.h4,{id:"basic-llm-integration",children:"Basic LLM Integration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import openai\nimport json\nfrom typing import List, Dict, Any\nimport rospy\n\nclass LLMBasedPlanner:\n    def __init__(self, api_key: str, model: str = "gpt-4"):\n        openai.api_key = api_key\n        self.model = model\n        self.ros_actions = self.get_available_ros_actions()\n\n    def get_available_ros_actions(self) -> List[Dict[str, Any]]:\n        """Define available ROS actions for the LLM to use"""\n        return [\n            {\n                "name": "move_to",\n                "description": "Move robot to a specific location",\n                "parameters": {\n                    "type": "object",\n                    "properties": {\n                        "x": {"type": "number", "description": "X coordinate"},\n                        "y": {"type": "number", "description": "Y coordinate"},\n                        "theta": {"type": "number", "description": "Orientation in radians"}\n                    },\n                    "required": ["x", "y", "theta"]\n                }\n            },\n            {\n                "name": "pick_object",\n                "description": "Pick up an object at the current location",\n                "parameters": {\n                    "type": "object",\n                    "properties": {\n                        "object_name": {"type": "string", "description": "Name of the object to pick"}\n                    },\n                    "required": ["object_name"]\n                }\n            },\n            {\n                "name": "place_object",\n                "description": "Place the currently held object at the current location",\n                "parameters": {\n                    "type": "object",\n                    "properties": {\n                        "object_name": {"type": "string", "description": "Name of the object to place"}\n                    },\n                    "required": ["object_name"]\n                }\n            }\n        ]\n\n    def plan_from_goal(self, goal: str) -> List[Dict[str, Any]]:\n        """Generate a plan from a natural language goal"""\n        prompt = f"""\n        You are a cognitive planner for a humanoid robot. Given the following goal,\n        break it down into a sequence of executable actions.\n        The available actions are: {json.dumps(self.ros_actions)}\n\n        Goal: {goal}\n\n        Return the plan as a JSON list of actions, where each action has:\n        - name: the action name\n        - parameters: the action parameters\n\n        Example response:\n        [\n            {{"name": "move_to", "parameters": {{"x": 1.0, "y": 2.0, "theta": 0.0}}},\n            {{"name": "pick_object", "parameters": {{"object_name": "red_cup"}}}\n        ]\n        """\n\n        response = openai.ChatCompletion.create(\n            model=self.model,\n            messages=[{"role": "user", "content": prompt}],\n            temperature=0.1\n        )\n\n        plan_text = response.choices[0].message.content\n        try:\n            # Extract JSON from the response\n            start_idx = plan_text.find(\'[\')\n            end_idx = plan_text.rfind(\']\') + 1\n            plan_json = plan_text[start_idx:end_idx]\n            plan = json.loads(plan_json)\n            return plan\n        except json.JSONDecodeError:\n            rospy.logerr(f"Failed to parse plan: {plan_text}")\n            return []\n'})}),"\n",(0,i.jsx)(e.h3,{id:"2-goal-decomposition-techniques",children:"2. Goal Decomposition Techniques"}),"\n",(0,i.jsx)(e.p,{children:"Goal decomposition is crucial for breaking down complex tasks into manageable subtasks that the robot can execute."}),"\n",(0,i.jsx)(e.h4,{id:"hierarchical-task-decomposition",children:"Hierarchical Task Decomposition"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class GoalDecomposer:\n    def __init__(self):\n        self.subgoal_templates = {\n            "complex_navigation": [\n                "find_path_to_destination",\n                "navigate_safely",\n                "reach_destination"\n            ],\n            "object_manipulation": [\n                "locate_object",\n                "approach_object",\n                "grasp_object",\n                "transport_object",\n                "place_object"\n            ],\n            "multi_room_task": [\n                "navigate_to_room",\n                "perform_task_in_room",\n                "return_to_base"\n            ]\n        }\n\n    def decompose_goal(self, goal: str) -> List[str]:\n        """Decompose a high-level goal into subgoals"""\n        # This is a simplified example - in practice, you\'d use an LLM for this\n        if "kitchen" in goal.lower() and ("get" in goal.lower() or "bring" in goal.lower()):\n            return [\n                "navigate to kitchen",\n                "locate requested item",\n                "grasp the item",\n                "return to original location",\n                "deliver the item"\n            ]\n\n        elif "clean" in goal.lower():\n            return [\n                "identify dirty areas",\n                "navigate to first area",\n                "clean the area",\n                "check if area is clean",\n                "move to next area if needed"\n            ]\n\n        else:\n            # For unknown goals, return the original goal as a single subgoal\n            return [goal]\n'})}),"\n",(0,i.jsx)(e.h3,{id:"3-task-sequencing-with-llms",children:"3. Task Sequencing with LLMs"}),"\n",(0,i.jsx)(e.p,{children:"Sequencing tasks properly is essential for successful robot execution:"}),"\n",(0,i.jsx)(e.h4,{id:"sequential-task-planner",children:"Sequential Task Planner"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class SequentialTaskPlanner:\n    def __init__(self):\n        self.dependencies = {\n            "grasp_object": ["approach_object"],\n            "place_object": ["transport_object"],\n            "transport_object": ["grasp_object"],\n            "navigate_safely": ["find_path_to_destination"]\n        }\n\n    def order_tasks(self, tasks: List[str]) -> List[str]:\n        """Order tasks based on dependencies"""\n        ordered_tasks = []\n        remaining_tasks = tasks.copy()\n\n        while remaining_tasks:\n            for task in remaining_tasks:\n                # Check if all dependencies are satisfied\n                deps_satisfied = True\n                if task in self.dependencies:\n                    for dep in self.dependencies[task]:\n                        if dep not in ordered_tasks:\n                            deps_satisfied = False\n                            break\n\n                if deps_satisfied:\n                    ordered_tasks.append(task)\n                    remaining_tasks.remove(task)\n                    break\n            else:\n                # If no task can be added, there might be circular dependencies\n                rospy.logwarn(f"Could not satisfy dependencies for remaining tasks: {remaining_tasks}")\n                break\n\n        return ordered_tasks\n'})}),"\n",(0,i.jsx)(e.h3,{id:"4-prompt-engineering-examples-for-robotics",children:"4. Prompt Engineering Examples for Robotics"}),"\n",(0,i.jsx)(e.p,{children:"Effective prompt engineering is crucial for getting reliable responses from LLMs in robotics contexts:"}),"\n",(0,i.jsx)(e.h4,{id:"context-aware-prompting",children:"Context-Aware Prompting"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class RobotPromptEngineer:\n    def __init__(self):\n        self.robot_capabilities = {\n            "navigation": True,\n            "manipulation": True,\n            "perception": True,\n            "speech": True\n        }\n        self.environment = {\n            "rooms": ["kitchen", "living room", "bedroom", "office"],\n            "objects": ["cup", "book", "phone", "keys", "bottle"],\n            "locations": {\n                "kitchen": {"x": 1.0, "y": 2.0},\n                "living room": {"x": 3.0, "y": 1.0},\n                "bedroom": {"x": 0.0, "y": 4.0},\n                "office": {"x": 2.5, "y": 3.5}\n            }\n        }\n\n    def create_contextual_prompt(self, goal: str) -> str:\n        """Create a contextual prompt for the LLM"""\n        return f"""\n        You are a cognitive planner for a humanoid robot with the following capabilities:\n        {json.dumps(self.robot_capabilities)}\n\n        The environment contains these rooms:\n        {json.dumps(self.environment[\'rooms\'])}\n\n        The environment contains these objects:\n        {json.dumps(self.environment[\'objects\'])}\n\n        Room locations:\n        {json.dumps(self.environment[\'locations\'])}\n\n        Given the goal: "{goal}"\n\n        Generate a sequence of actions that the robot can execute to achieve this goal.\n        Consider the environment layout and robot capabilities.\n        Each action should be specific and executable.\n\n        Format your response as a JSON list of actions with the following structure:\n        [\n            {{\n                "action": "action_name",\n                "parameters": {{"param1": "value1", "param2": "value2"}},\n                "reasoning": "Brief explanation of why this action is needed"\n            }}\n        ]\n\n        Actions available:\n        - move_to: Move to a specific location (x, y coordinates)\n        - locate_object: Find an object in the environment\n        - grasp_object: Pick up an object\n        - place_object: Place an object at current location\n        - speak: Make the robot speak a message\n        """\n'})}),"\n",(0,i.jsx)(e.h3,{id:"5-error-handling-and-replanning-strategies",children:"5. Error Handling and Replanning Strategies"}),"\n",(0,i.jsx)(e.p,{children:"Robots often encounter unexpected situations that require replanning:"}),"\n",(0,i.jsx)(e.h4,{id:"robust-planning-with-error-handling",children:"Robust Planning with Error Handling"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class RobustPlanner:\n    def __init__(self):\n        self.max_replan_attempts = 3\n        self.error_recovery_strategies = {\n            "navigation_failure": ["use_alternative_path", "request_assistance"],\n            "object_not_found": ["search_alternative_locations", "ask_for_help"],\n            "grasp_failure": ["retry_grasp", "use_different_approach", "abandon_task"]\n        }\n\n    def execute_plan_with_error_handling(self, plan: List[Dict], robot_state: Dict):\n        """Execute a plan with error handling and replanning"""\n        current_step = 0\n\n        while current_step < len(plan):\n            action = plan[current_step]\n\n            try:\n                # Execute the action\n                success = self.execute_action(action, robot_state)\n\n                if success:\n                    current_step += 1\n                    rospy.loginfo(f"Completed action: {action[\'action\']}")\n                else:\n                    # Handle failure\n                    rospy.logwarn(f"Action failed: {action[\'action\']}")\n                    recovery_success = self.handle_action_failure(\n                        action, robot_state, plan, current_step\n                    )\n\n                    if not recovery_success:\n                        rospy.logerr("Could not recover from action failure")\n                        return False\n\n            except Exception as e:\n                rospy.logerr(f"Exception during action execution: {e}")\n                return False\n\n        return True\n\n    def handle_action_failure(self, failed_action: Dict, robot_state: Dict,\n                             plan: List[Dict], step_index: int) -> bool:\n        """Handle action failure with potential replanning"""\n        error_type = self.classify_error(failed_action, robot_state)\n\n        if error_type in self.error_recovery_strategies:\n            strategies = self.error_recovery_strategies[error_type]\n\n            for strategy in strategies:\n                if self.apply_recovery_strategy(strategy, failed_action, robot_state, plan, step_index):\n                    return True\n\n        # If all recovery strategies fail, try replanning\n        return self.replan_after_failure(failed_action, robot_state, plan, step_index)\n\n    def replan_after_failure(self, failed_action: Dict, robot_state: Dict,\n                            plan: List[Dict], step_index: int) -> bool:\n        """Replan the remaining tasks after a failure"""\n        rospy.loginfo("Attempting to replan after failure...")\n\n        # For simplicity, this is a basic replanning\n        # In practice, you\'d use the LLM to generate a new plan\n        remaining_goal = self.extract_remaining_goal(plan, step_index)\n\n        if remaining_goal:\n            new_plan = self.generate_new_plan(remaining_goal, robot_state)\n            if new_plan:\n                # Execute the new plan\n                return self.execute_plan_with_error_handling(new_plan, robot_state)\n\n        return False\n'})}),"\n",(0,i.jsx)(e.h3,{id:"6-safety-constraints-implementation",children:"6. Safety Constraints Implementation"}),"\n",(0,i.jsx)(e.p,{children:"Safety is paramount in robotics applications:"}),"\n",(0,i.jsx)(e.h4,{id:"safety-constrained-planning",children:"Safety-Constrained Planning"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class SafetyConstrainedPlanner:\n    def __init__(self):\n        self.safety_constraints = {\n            "no_go_zones": [],  # List of coordinates to avoid\n            "speed_limits": {"indoor": 0.5, "outdoor": 1.0},  # m/s\n            "object_handling": {"fragile_objects": ["glass", "ceramic"]},\n            "human_proximity": {"minimum_distance": 0.5}  # meters\n        }\n\n    def validate_plan_safety(self, plan: List[Dict]) -> bool:\n        """Validate that a plan meets safety constraints"""\n        for action in plan:\n            if not self.is_action_safe(action):\n                return False\n        return True\n\n    def is_action_safe(self, action: Dict) -> bool:\n        """Check if a single action is safe"""\n        action_type = action.get("action", "")\n\n        if action_type == "move_to":\n            target_location = action.get("parameters", {}).get("x", 0), action.get("parameters", {}).get("y", 0)\n            return self.is_navigation_safe(target_location)\n\n        elif action_type == "grasp_object":\n            obj_name = action.get("parameters", {}).get("object_name", "")\n            return self.is_object_safe_to_grasp(obj_name)\n\n        # Add more safety checks for other action types\n        return True\n\n    def is_navigation_safe(self, location: tuple) -> bool:\n        """Check if navigation to a location is safe"""\n        # Check if location is in no-go zone\n        for no_go_zone in self.safety_constraints["no_go_zones"]:\n            if self.distance(location, no_go_zone) < 0.5:  # 0.5m threshold\n                return False\n        return True\n\n    def is_object_safe_to_grasp(self, obj_name: str) -> bool:\n        """Check if it\'s safe to grasp an object"""\n        fragile_objects = self.safety_constraints["object_handling"]["fragile_objects"]\n        return obj_name.lower() not in [obj.lower() for obj in fragile_objects]\n\n    def distance(self, pos1: tuple, pos2: tuple) -> float:\n        """Calculate Euclidean distance between two points"""\n        return ((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)**0.5\n'})}),"\n",(0,i.jsx)(e.h3,{id:"7-complete-cognitive-planning-system",children:"7. Complete Cognitive Planning System"}),"\n",(0,i.jsx)(e.p,{children:"Here's a complete implementation combining all the components:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rospy\nimport openai\nimport json\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import PoseStamped\nimport time\n\nclass CompleteCognitivePlanner:\n    def __init__(self, openai_api_key: str):\n        rospy.init_node(\'cognitive_planner\')\n        openai.api_key = openai_api_key\n\n        # Initialize components\n        self.llm_planner = LLMBasedPlanner(openai_api_key)\n        self.goal_decomposer = GoalDecomposer()\n        self.task_sequencer = SequentialTaskPlanner()\n        self.prompt_engineer = RobotPromptEngineer()\n        self.robust_planner = RobustPlanner()\n        self.safety_planner = SafetyConstrainedPlanner()\n\n        # Publishers and subscribers\n        self.goal_sub = rospy.Subscriber(\'/natural_language_goals\', String, self.goal_callback)\n        self.action_pub = rospy.Publisher(\'/robot_action_queue\', String, queue_size=10)\n        self.status_pub = rospy.Publisher(\'/planning_status\', String, queue_size=10)\n\n        rospy.loginfo("Cognitive Planning System initialized")\n\n    def goal_callback(self, msg):\n        """Process incoming natural language goals"""\n        goal = msg.data\n        rospy.loginfo(f"Received goal: {goal}")\n\n        # Publish planning status\n        status_msg = String()\n        status_msg.data = f"Planning for goal: {goal}"\n        self.status_pub.publish(status_msg)\n\n        # Plan the task\n        plan = self.plan_for_goal(goal)\n\n        if plan:\n            # Validate plan safety\n            if self.safety_planner.validate_plan_safety(plan):\n                # Execute the plan with error handling\n                success = self.robust_planner.execute_plan_with_error_handling(plan, {})\n\n                if success:\n                    rospy.loginfo("Plan executed successfully")\n                    status_msg.data = "Plan completed successfully"\n                else:\n                    rospy.logerr("Plan execution failed")\n                    status_msg.data = "Plan execution failed"\n            else:\n                rospy.logerr("Plan failed safety validation")\n                status_msg.data = "Plan failed safety validation"\n        else:\n            rospy.logerr("Could not generate plan for goal")\n            status_msg.data = "Could not generate plan"\n\n        self.status_pub.publish(status_msg)\n\n    def plan_for_goal(self, goal: str) -> List[Dict]:\n        """Generate a plan for a given goal"""\n        # Decompose the goal\n        subgoals = self.goal_decomposer.decompose_goal(goal)\n\n        # Generate plan for each subgoal\n        full_plan = []\n        for subgoal in subgoals:\n            # Use LLM to generate detailed plan for subgoal\n            subgoal_plan = self.llm_planner.plan_from_goal(subgoal)\n            full_plan.extend(subgoal_plan)\n\n        # Order tasks based on dependencies\n        ordered_plan = self.task_sequencer.order_tasks(full_plan)\n\n        return ordered_plan\n\n    def run(self):\n        """Run the cognitive planning system"""\n        rospy.spin()\n\nif __name__ == \'__main__\':\n    # You would need to provide your OpenAI API key here\n    # planner = CompleteCognitivePlanner("your-api-key-here")\n    # planner.run()\n    pass\n'})}),"\n",(0,i.jsx)(e.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Students can integrate LLMs for cognitive planning in robotics applications"}),"\n",(0,i.jsx)(e.li,{children:"Students can apply effective goal decomposition and task sequencing techniques"}),"\n",(0,i.jsx)(e.li,{children:"Students can translate natural language goals into executable ROS 2 action sequences"}),"\n",(0,i.jsx)(e.li,{children:"Students can create well-engineered prompts for robotics applications"}),"\n",(0,i.jsx)(e.li,{children:"Students can implement robust error handling and replanning strategies"}),"\n",(0,i.jsx)(e.li,{children:"Students can incorporate safety constraints into cognitive planning systems"}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},8453(n,e,t){t.d(e,{R:()=>s,x:()=>r});var a=t(6540);const i={},o=a.createContext(i);function s(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),a.createElement(o.Provider,{value:e},n.children)}}}]);