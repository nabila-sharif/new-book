"use strict";(self.webpackChunkfrontend_book=self.webpackChunkfrontend_book||[]).push([[3875],{5324(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2/chapter-2-content","title":"Chapter 2: High-Fidelity Environments with Unity","description":"Introduction to Unity for Robotic Simulation","source":"@site/docs/module-2/chapter-2-content.md","sourceDirName":"module-2","slug":"/module-2/chapter-2-content","permalink":"/docs/module-2/chapter-2-content","draft":false,"unlisted":false,"editUrl":"https://github.com/nabila-sharif/AI---Humanoid-Robotics-Book/tree/main/frontend_book/docs/module-2/chapter-2-content.md","tags":[],"version":"current","frontMatter":{},"sidebar":"module2Sidebar","previous":{"title":"Chapter 1: Physics Simulation with Gazebo","permalink":"/docs/module-2/chapter-1-content"},"next":{"title":"Chapter 3: Sensor Simulation & Fidelity","permalink":"/docs/module-2/chapter-3-content"}}');var r=i(4848),o=i(8453);const a={},s="Chapter 2: High-Fidelity Environments with Unity",l={},c=[{value:"Introduction to Unity for Robotic Simulation",id:"introduction-to-unity-for-robotic-simulation",level:2},{value:"Creating High-Fidelity Environments for Humanoids",id:"creating-high-fidelity-environments-for-humanoids",level:2},{value:"Unity Rendering Pipelines",id:"unity-rendering-pipelines",level:3},{value:"Built-in Render Pipeline",id:"built-in-render-pipeline",level:4},{value:"Universal Render Pipeline (URP)",id:"universal-render-pipeline-urp",level:4},{value:"High Definition Render Pipeline (HDRP)",id:"high-definition-render-pipeline-hdrp",level:4},{value:"Environment Setup Example",id:"environment-setup-example",level:3},{value:"Creating Realistic Indoor Environments",id:"creating-realistic-indoor-environments",level:3},{value:"Room Layout Design",id:"room-layout-design",level:4},{value:"Surface Materials",id:"surface-materials",level:4},{value:"Outdoor Environment Considerations",id:"outdoor-environment-considerations",level:3},{value:"Human-Robot Interaction Scenarios",id:"human-robot-interaction-scenarios",level:2},{value:"Interaction Design Principles",id:"interaction-design-principles",level:3},{value:"Implementing Interaction Scenarios",id:"implementing-interaction-scenarios",level:3},{value:"Safety Considerations in Interaction Design",id:"safety-considerations-in-interaction-design",level:3},{value:"Unity-ROS Communication Workflow",id:"unity-ros-communication-workflow",level:2},{value:"Setting up ROS-TCP-Connector",id:"setting-up-ros-tcp-connector",level:3},{value:"Basic ROS Connection Setup",id:"basic-ros-connection-setup",level:3},{value:"Sensor Data Integration",id:"sensor-data-integration",level:3},{value:"Performance and Realism Trade-offs",id:"performance-and-realism-trade-offs",level:2},{value:"Balancing Visual Quality and Performance",id:"balancing-visual-quality-and-performance",level:3},{value:"Quality Settings for Robotics",id:"quality-settings-for-robotics",level:4},{value:"Optimization Techniques",id:"optimization-techniques",level:4},{value:"Realism vs. Performance Matrix",id:"realism-vs-performance-matrix",level:3},{value:"Best Practices for Unity-Based Robotic Simulation",id:"best-practices-for-unity-based-robotic-simulation",level:2},{value:"Asset Optimization",id:"asset-optimization",level:3},{value:"Simulation Accuracy",id:"simulation-accuracy",level:3},{value:"Integration Considerations",id:"integration-considerations",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"chapter-2-high-fidelity-environments-with-unity",children:"Chapter 2: High-Fidelity Environments with Unity"})}),"\n",(0,r.jsx)(e.h2,{id:"introduction-to-unity-for-robotic-simulation",children:"Introduction to Unity for Robotic Simulation"}),"\n",(0,r.jsx)(e.p,{children:"Unity has emerged as a powerful platform for creating high-fidelity visual environments for robotics simulation. Unlike traditional physics simulators, Unity excels at creating photorealistic environments with advanced rendering capabilities, making it ideal for testing perception algorithms, human-robot interaction scenarios, and visual-based navigation systems."}),"\n",(0,r.jsx)(e.p,{children:"The key advantages of using Unity for robotic simulation include:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Advanced rendering pipelines (Built-in, URP, HDRP)"}),"\n",(0,r.jsx)(e.li,{children:"Photorealistic lighting and materials"}),"\n",(0,r.jsx)(e.li,{children:"Extensive asset library and environment creation tools"}),"\n",(0,r.jsx)(e.li,{children:"VR/AR support for immersive interaction"}),"\n",(0,r.jsx)(e.li,{children:"Cross-platform deployment capabilities"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"creating-high-fidelity-environments-for-humanoids",children:"Creating High-Fidelity Environments for Humanoids"}),"\n",(0,r.jsx)(e.h3,{id:"unity-rendering-pipelines",children:"Unity Rendering Pipelines"}),"\n",(0,r.jsx)(e.p,{children:"Unity offers three main rendering pipeline options:"}),"\n",(0,r.jsx)(e.h4,{id:"built-in-render-pipeline",children:"Built-in Render Pipeline"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Default pipeline with basic lighting and shading"}),"\n",(0,r.jsx)(e.li,{children:"Good performance for simple scenes"}),"\n",(0,r.jsx)(e.li,{children:"Limited advanced rendering features"}),"\n",(0,r.jsx)(e.li,{children:"Suitable for basic perception testing"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"universal-render-pipeline-urp",children:"Universal Render Pipeline (URP)"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Lightweight, optimized for performance"}),"\n",(0,r.jsx)(e.li,{children:"Good balance between quality and performance"}),"\n",(0,r.jsx)(e.li,{children:"Supports 2D and 3D rendering"}),"\n",(0,r.jsx)(e.li,{children:"Ideal for real-time robotic applications"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"high-definition-render-pipeline-hdrp",children:"High Definition Render Pipeline (HDRP)"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Advanced rendering with physically-based lighting"}),"\n",(0,r.jsx)(e.li,{children:"High-quality shadows, reflections, and post-processing"}),"\n",(0,r.jsx)(e.li,{children:"Best for photorealistic environments"}),"\n",(0,r.jsx)(e.li,{children:"Higher computational requirements"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"environment-setup-example",children:"Environment Setup Example"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.Rendering;\n\npublic class EnvironmentSetup : MonoBehaviour\n{\n    [Header("Lighting Configuration")]\n    public Light sunLight;\n    public Gradient skyGradient;\n\n    [Header("Environment Materials")]\n    public Material groundMaterial;\n    public Material wallMaterial;\n\n    void Start()\n    {\n        // Configure lighting\n        ConfigureLighting();\n\n        // Set up materials\n        ConfigureMaterials();\n\n        // Optimize for robotic simulation\n        OptimizeForSimulation();\n    }\n\n    void ConfigureLighting()\n    {\n        // Set up realistic sun light\n        sunLight.type = LightType.Directional;\n        sunLight.intensity = 1.0f;\n        sunLight.color = Color.white;\n\n        // Configure shadows\n        sunLight.shadows = LightShadows.Soft;\n        sunLight.shadowStrength = 0.8f;\n    }\n\n    void ConfigureMaterials()\n    {\n        // Ground material with realistic properties\n        groundMaterial.EnableKeyword("_METALLICGLOSSMAP");\n        groundMaterial.SetFloat("_Metallic", 0.1f);\n        groundMaterial.SetFloat("_Smoothness", 0.3f);\n    }\n\n    void OptimizeForSimulation()\n    {\n        // Reduce render quality for better performance\n        QualitySettings.vSyncCount = 0;\n        Application.targetFrameRate = 60;\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"creating-realistic-indoor-environments",children:"Creating Realistic Indoor Environments"}),"\n",(0,r.jsx)(e.p,{children:"For humanoid robots, realistic indoor environments are crucial for testing navigation and interaction capabilities:"}),"\n",(0,r.jsx)(e.h4,{id:"room-layout-design",children:"Room Layout Design"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Create accurate room dimensions based on real-world spaces"}),"\n",(0,r.jsx)(e.li,{children:"Include furniture and obstacles that humanoid robots might encounter"}),"\n",(0,r.jsx)(e.li,{children:"Ensure proper scale for humanoid proportions (typically 2-3 meters ceiling height)"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"surface-materials",children:"Surface Materials"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use PBR materials for realistic lighting response"}),"\n",(0,r.jsx)(e.li,{children:"Configure friction properties for different surfaces"}),"\n",(0,r.jsx)(e.li,{children:"Include texture variations for visual recognition"}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:"public class SurfaceMaterialManager : MonoBehaviour\n{\n    public Material[] surfaceMaterials;\n\n    [System.Serializable]\n    public class SurfaceProperties\n    {\n        public string surfaceType;\n        public float frictionCoefficient;\n        public float restitution;\n        public PhysicMaterial physicMaterial;\n    }\n\n    public SurfaceProperties[] surfaceProperties;\n\n    void Start()\n    {\n        InitializeSurfaceMaterials();\n    }\n\n    void InitializeSurfaceMaterials()\n    {\n        foreach (var prop in surfaceProperties)\n        {\n            prop.physicMaterial = new PhysicMaterial();\n            prop.physicMaterial.staticFriction = prop.frictionCoefficient;\n            prop.physicMaterial.dynamicFriction = prop.frictionCoefficient;\n            prop.physicMaterial.bounciness = prop.restitution;\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(e.h3,{id:"outdoor-environment-considerations",children:"Outdoor Environment Considerations"}),"\n",(0,r.jsx)(e.p,{children:"For humanoid robots that operate outdoors, consider:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Dynamic lighting conditions throughout the day"}),"\n",(0,r.jsx)(e.li,{children:"Weather effects (rain, snow, fog)"}),"\n",(0,r.jsx)(e.li,{children:"Terrain variations (grass, pavement, uneven surfaces)"}),"\n",(0,r.jsx)(e.li,{children:"Natural obstacles (trees, rocks, water)"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"human-robot-interaction-scenarios",children:"Human-Robot Interaction Scenarios"}),"\n",(0,r.jsx)(e.h3,{id:"interaction-design-principles",children:"Interaction Design Principles"}),"\n",(0,r.jsx)(e.p,{children:"Creating effective human-robot interaction scenarios requires careful consideration of:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Intuitive Control Interfaces"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Natural Communication Methods"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Safety Protocols"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Feedback Systems"})}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"implementing-interaction-scenarios",children:"Implementing Interaction Scenarios"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections;\n\npublic class HumanRobotInteraction : MonoBehaviour\n{\n    [Header("Interaction Components")]\n    public GameObject humanoidRobot;\n    public Camera mainCamera;\n    public LayerMask interactionMask;\n\n    [Header("Interaction Parameters")]\n    public float interactionDistance = 2.0f;\n    public float interactionCooldown = 0.5f;\n\n    private bool canInteract = true;\n    private GameObject currentTarget;\n\n    void Update()\n    {\n        HandleInteractionInput();\n    }\n\n    void HandleInteractionInput()\n    {\n        if (Input.GetMouseButtonDown(0) && canInteract)\n        {\n            Ray ray = mainCamera.ScreenPointToRay(Input.mousePosition);\n            RaycastHit hit;\n\n            if (Physics.Raycast(ray, out hit, interactionDistance, interactionMask))\n            {\n                currentTarget = hit.collider.gameObject;\n                StartCoroutine(ProcessInteraction());\n            }\n        }\n    }\n\n    IEnumerator ProcessInteraction()\n    {\n        canInteract = false;\n\n        // Process the interaction\n        if (currentTarget.CompareTag("InteractiveObject"))\n        {\n            ProcessObjectInteraction(currentTarget);\n        }\n        else if (currentTarget.CompareTag("HumanoidRobot"))\n        {\n            ProcessRobotInteraction(currentTarget);\n        }\n\n        yield return new WaitForSeconds(interactionCooldown);\n        canInteract = true;\n    }\n\n    void ProcessObjectInteraction(GameObject target)\n    {\n        // Handle object-specific interactions\n        Debug.Log("Interacting with object: " + target.name);\n    }\n\n    void ProcessRobotInteraction(GameObject robot)\n    {\n        // Handle robot-specific interactions\n        Debug.Log("Interacting with robot: " + robot.name);\n\n        // Example: Send command to robot\n        SendRobotCommand(robot, "GREET");\n    }\n\n    void SendRobotCommand(GameObject robot, string command)\n    {\n        // In a real implementation, this would communicate with ROS\n        Debug.Log("Sending command to robot: " + command);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"safety-considerations-in-interaction-design",children:"Safety Considerations in Interaction Design"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Implement collision avoidance systems"}),"\n",(0,r.jsx)(e.li,{children:"Set safe interaction boundaries"}),"\n",(0,r.jsx)(e.li,{children:"Include emergency stop functionality"}),"\n",(0,r.jsx)(e.li,{children:"Provide clear visual feedback for robot state"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"unity-ros-communication-workflow",children:"Unity-ROS Communication Workflow"}),"\n",(0,r.jsx)(e.h3,{id:"setting-up-ros-tcp-connector",children:"Setting up ROS-TCP-Connector"}),"\n",(0,r.jsx)(e.p,{children:"The ROS-TCP-Connector enables communication between Unity and ROS systems:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Install ROS-TCP-Connector package"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Configure network settings"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Implement message serialization"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Handle connection management"})}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"basic-ros-connection-setup",children:"Basic ROS Connection Setup"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections;\nusing Unity.Robotics.ROSTCPConnector;\nusing Unity.Robotics.ROSTCPConnector.MessageGeneration;\n\npublic class ROSConnectionManager : MonoBehaviour\n{\n    [Header("ROS Connection Settings")]\n    public string rosIPAddress = "127.0.0.1";\n    public int rosPort = 10000;\n\n    [Header("Robot Configuration")]\n    public string robotName = "humanoid_robot";\n\n    private ROSConnection rosConnection;\n\n    void Start()\n    {\n        ConnectToROS();\n    }\n\n    void ConnectToROS()\n    {\n        rosConnection = ROSConnection.GetOrCreateInstance();\n        rosConnection.rosIPAddress = rosIPAddress;\n        rosConnection.rosPort = rosPort;\n\n        // Register topics\n        rosConnection.RegisterPublisher<sensor_msgs.JointState>("/joint_states");\n        rosConnection.RegisterSubscriber<sensor_msgs.JointState>("/joint_states", OnJointStateReceived);\n\n        Debug.Log("Connected to ROS at " + rosIPAddress + ":" + rosPort);\n    }\n\n    void OnJointStateReceived(sensor_msgs.JointState jointState)\n    {\n        // Process joint state data\n        UpdateRobotJoints(jointState);\n    }\n\n    void UpdateRobotJoints(sensor_msgs.JointState jointState)\n    {\n        // Update Unity robot model based on ROS joint states\n        for (int i = 0; i < jointState.name.Count; i++)\n        {\n            string jointName = jointState.name[i];\n            float jointPosition = (float)jointState.position[i];\n\n            Transform jointTransform = FindJointByName(jointName);\n            if (jointTransform != null)\n            {\n                // Update joint rotation based on ROS data\n                jointTransform.localRotation = Quaternion.Euler(0, jointPosition * Mathf.Rad2Deg, 0);\n            }\n        }\n    }\n\n    Transform FindJointByName(string jointName)\n    {\n        // Find joint transform in the robot hierarchy\n        Transform[] allChildren = GetComponentsInChildren<Transform>();\n        foreach (Transform child in allChildren)\n        {\n            if (child.name == jointName)\n                return child;\n        }\n        return null;\n    }\n\n    void OnDestroy()\n    {\n        if (rosConnection != null)\n        {\n            rosConnection.Close();\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"sensor-data-integration",children:"Sensor Data Integration"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector.MessageGeneration;\n\npublic class SensorDataHandler : MonoBehaviour\n{\n    [Header("Sensor Topics")]\n    public string cameraTopic = "/camera/rgb/image_raw";\n    public string lidarTopic = "/scan";\n    public string imuTopic = "/imu/data";\n\n    void Start()\n    {\n        // Subscribe to sensor topics\n        ROSConnection.GetOrCreateInstance()\n            .Subscribe<sensor_msgs.Image>(cameraTopic, OnCameraDataReceived);\n\n        ROSConnection.GetOrCreateInstance()\n            .Subscribe<sensor_msgs.LaserScan>(lidarTopic, OnLidarDataReceived);\n\n        ROSConnection.GetOrCreateInstance()\n            .Subscribe<sensor_msgs.Imu>(imuTopic, OnIMUDataReceived);\n    }\n\n    void OnCameraDataReceived(sensor_msgs.Image image)\n    {\n        // Process camera image data\n        Texture2D cameraTexture = ConvertImageToTexture(image);\n        UpdateCameraTexture(cameraTexture);\n    }\n\n    void OnLidarDataReceived(sensor_msgs.LaserScan scan)\n    {\n        // Process LIDAR scan data\n        ProcessLidarScan(scan);\n    }\n\n    void OnIMUDataReceived(sensor_msgs.Imu imu)\n    {\n        // Process IMU data\n        UpdateRobotOrientation(imu.orientation);\n        UpdateRobotAcceleration(imu.linear_acceleration);\n    }\n\n    Texture2D ConvertImageToTexture(sensor_msgs.Image image)\n    {\n        // Convert ROS image message to Unity texture\n        Texture2D texture = new Texture2D((int)image.width, (int)image.height, TextureFormat.RGB24, false);\n        texture.LoadRawTextureData(image.data);\n        texture.Apply();\n        return texture;\n    }\n\n    void UpdateCameraTexture(Texture2D texture)\n    {\n        // Update material or UI element with camera texture\n        Renderer renderer = GetComponent<Renderer>();\n        if (renderer != null)\n        {\n            renderer.material.mainTexture = texture;\n        }\n    }\n\n    void ProcessLidarScan(sensor_msgs.LaserScan scan)\n    {\n        // Process LIDAR data for visualization or navigation\n        Debug.Log("Received LIDAR scan with " + scan.ranges.Count + " points");\n    }\n\n    void UpdateRobotOrientation(geometry_msgs.Quaternion orientation)\n    {\n        // Update robot orientation based on IMU data\n        transform.rotation = new Quaternion(\n            (float)orientation.x,\n            (float)orientation.y,\n            (float)orientation.z,\n            (float)orientation.w\n        );\n    }\n\n    void UpdateRobotAcceleration(geometry_msgs.Vector3 acceleration)\n    {\n        // Process linear acceleration data\n        Debug.Log("Linear acceleration: " + acceleration);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h2,{id:"performance-and-realism-trade-offs",children:"Performance and Realism Trade-offs"}),"\n",(0,r.jsx)(e.h3,{id:"balancing-visual-quality-and-performance",children:"Balancing Visual Quality and Performance"}),"\n",(0,r.jsx)(e.p,{children:"For robotic simulation, finding the right balance between visual fidelity and performance is crucial:"}),"\n",(0,r.jsx)(e.h4,{id:"quality-settings-for-robotics",children:"Quality Settings for Robotics"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:"public class RoboticsQualitySettings : MonoBehaviour\n{\n    public enum QualityLevel\n    {\n        Performance,    // Lower quality, higher frame rate\n        Balanced,       // Medium quality, good performance\n        Quality         // High quality, lower frame rate\n    }\n\n    public QualityLevel currentQuality = QualityLevel.Balanced;\n\n    void Start()\n    {\n        ApplyQualitySettings();\n    }\n\n    void ApplyQualitySettings()\n    {\n        switch (currentQuality)\n        {\n            case QualityLevel.Performance:\n                QualitySettings.SetQualityLevel(0);\n                QualitySettings.vSyncCount = 0;\n                Application.targetFrameRate = 60;\n                break;\n\n            case QualityLevel.Balanced:\n                QualitySettings.SetQualityLevel(1);\n                QualitySettings.vSyncCount = 1;\n                Application.targetFrameRate = 30;\n                break;\n\n            case QualityLevel.Quality:\n                QualitySettings.SetQualityLevel(2);\n                QualitySettings.vSyncCount = 1;\n                Application.targetFrameRate = 30;\n                break;\n        }\n    }\n}\n"})}),"\n",(0,r.jsx)(e.h4,{id:"optimization-techniques",children:"Optimization Techniques"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Level of Detail (LOD) Systems"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Occlusion Culling"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Texture Streaming"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.strong,{children:"Dynamic Batching"})}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"realism-vs-performance-matrix",children:"Realism vs. Performance Matrix"}),"\n",(0,r.jsx)(e.p,{children:"| Aspect | High Realism | Balanced | Performance |"}),"\n",(0,r.jsx)(e.p,{children:"|--------|--------------|----------|-------------|\n| Lighting | HDRP, Real-time GI | URP, Baked lighting | Built-in, Simple lighting |\n| Textures | 4K PBR materials | 2K textures | Compressed textures |\n| Shadows | High-res, soft shadows | Medium-res shadows | Low-res shadows |\n| Effects | Full post-processing | Limited effects | Minimal effects |\n| Frame Rate | 30 FPS | 30-60 FPS | 60+ FPS |"}),"\n",(0,r.jsx)(e.h2,{id:"best-practices-for-unity-based-robotic-simulation",children:"Best Practices for Unity-Based Robotic Simulation"}),"\n",(0,r.jsx)(e.h3,{id:"asset-optimization",children:"Asset Optimization"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use appropriate polygon counts for real-time performance"}),"\n",(0,r.jsx)(e.li,{children:"Implement texture atlasing for better draw call performance"}),"\n",(0,r.jsx)(e.li,{children:"Use occlusion culling for complex environments"}),"\n",(0,r.jsx)(e.li,{children:"Implement LOD systems for distant objects"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"simulation-accuracy",children:"Simulation Accuracy"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Validate visual properties against real-world references"}),"\n",(0,r.jsx)(e.li,{children:"Calibrate camera parameters to match physical sensors"}),"\n",(0,r.jsx)(e.li,{children:"Ensure proper scale relationships between objects"}),"\n",(0,r.jsx)(e.li,{children:"Test under various lighting conditions"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"integration-considerations",children:"Integration Considerations"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Maintain consistent coordinate systems between Unity and ROS"}),"\n",(0,r.jsx)(e.li,{children:"Implement proper time synchronization"}),"\n",(0,r.jsx)(e.li,{children:"Handle network latency in real-time applications"}),"\n",(0,r.jsx)(e.li,{children:"Include fallback mechanisms for connection failures"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"This chapter covered the creation of high-fidelity environments using Unity for digital twin applications in humanoid robotics. We explored rendering pipelines, environment creation techniques, human-robot interaction scenarios, and Unity-ROS integration. The balance between visual realism and performance is crucial for effective robotic simulation, and proper integration with ROS enables comprehensive digital twin functionality."})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>a,x:()=>s});var t=i(6540);const r={},o=t.createContext(r);function a(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);